{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550f773a",
   "metadata": {},
   "source": [
    "So the first source from onramp comes from Medium. Good ol lucky yours truly has a subscription, but if I did not, well I'd be f'd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f378c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effed():\n",
    "    print('Who needs an argument when you are effed from the start?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553901d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who needs an argument when you are effed from the start?\n"
     ]
    }
   ],
   "source": [
    "effed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab024a",
   "metadata": {},
   "source": [
    "But here I am, ready to go. \n",
    "[medium-rare](https://medium.com/analytics-vidhya/statistics-mean-median-mode-variance-standard-deviation-47fab926465a)\n",
    "\n",
    "So, it's an overview of Mean, Median, Mode, Variance and Standard Deviation. The bread and butter of statistics. Or if you prefer a gluten-free lifestyle, GF Ciabatta Rolls and I Cannot Believe it is Gluten-Free Margarine. \n",
    "\n",
    "Regardless of how basic these concepts may be, they are important; heck, they're essential. They're each facets of descriptive statistics, many of which are given via ```df.info()```. But without letting a computer do all of our thinking for us (-long, exasperated sigh of sloth-), let's explore their meaning in natural language. \n",
    "\n",
    "- Mean, a.k.a. the average of all the numbers in the data set (or subset). It is the sum of all data values divided by the number of data values. ```np.mean(target)``` does the trick. \n",
    "\n",
    "- Median: the mid value in an ordered data set. When the number of observations (n) is odd, the median value resolves from (n+1/2). When n is even, first find the value at the position (n/2) then find the value of (n+1/2) and then third, get the average of those two values. So, the sum of those two mid-number positions divided by two. \n",
    "\n",
    "- Mode: the most frequently occuring number in a data set (for my own sake, just to specify, the set will be conceptualized as column-based. The mode will be different for each column).\n",
    "\n",
    "- Variance: the numberical value that describes the variability (likelihood of chance or change) among the observations from their arithmetic mean, as denoted by sigma-squared. Variance measures spread. \n",
    "\n",
    "- Standard deviation: the square root of variance as a measure of dispersion amongst the observations. \n",
    "\n",
    "The phrasing in that medium article was pretty garbage. Or perhaps the automatic translation from whatever (presumably Hindi) to English was fallible. Whichever the case, that article was somewhat of a waste of time and it only confused my understanding of these basic concepts. So if anyone is reading this, don't shoot the messenger. In fact, don't shoot anyone. Gun violence is excessive enough as is. \n",
    "***\n",
    "The second source comes from Khan Academy. It's a video on Correlation and Causality. I like lectures from Khan; this should be good. \n",
    "\n",
    "This video gives me the inspiration for the title; a call-back to It's Always Sunny in Philadelphia. The video in summary: bwekfast.\n",
    "\n",
    "The study itself looked at correlation instead of cause and effect (causality), but mistakenly considered itself within the scope of causality. WebMD posited that \"Eating Breakfast May Beat Teen Obesity\". At least the 'may' acts as an intellectual fail-safe. The study itself fails to recognize underlying causes. i.e., activity causes habits of eating breakfast, versus breakfast facilitating heightened activity. Or, another example, maybe the causality is that those with higher BMI are less likely to experience hunger pangs in the morning. \n",
    "\n",
    "The phrase \"correlation does not imply causation\" refers to the inability to legitimately deduce a cause-and-effect relationship between two events or variables solely on the basis of an observed association or correlation between them. Accepting the counter-argument would be an example of committing a questionable-cause logical fallacy. \n",
    "\n",
    "Correlations only indicate that two factors move together, but not that they rely upon one another for that movement to occur. \n",
    "***\n",
    "Now we are hanging out with wallstreetmojo.com, and Mojo Jojo is not here (tragic). [This article] (https://www.wallstreetmojo.com/correlation-vs-covariance/) explores the difference(s) between covariance and correlation. Hopefully its readability outranks the Medium article by a metric fuckton. \n",
    "\n",
    "\"Covariance and correlation are two terms that are exactly opposite to each other. However, they both are used in statistics and regression analysis. Covariance shows us how the two variables vary, whereas correlation shows us the relationship and how they are related.\"\n",
    "\n",
    "I guess it's time to hit the plagiarization station via copy-pasta, but I just don't feel like retyping all this because...lazy? Nah, it's just more efficient to paste it when there's no benefit from changing its syntax or delivery. \n",
    "\n",
    "__Covariance__ measures how the two variables move concerning each other and is an extension of the concept of variance (which tells about how a single variable varies). It can take any value from -∞ to +∞.\n",
    "\n",
    "-  The higher this value, the more dependent the relationship is. A positive number signifies positive covariance and denotes a direct connection. Effectively this means that an increase in one variable would also lead to a corresponding increase in the other variable, provided other conditions remain constant.\n",
    "-  On the other hand, a negative number signifies negative covariance, which denotes an inverse relationship between the two variables. Though covariance is perfect for defining the type of relationship, it is not good for interpreting its magnitude.\n",
    "\n",
    "__Correlation__ is a step ahead of covariance as it quantifies the relationship between two random variables. In simple terms, it is a unit measure of how these variables change concerning each other (normalized covariance value).\n",
    "\n",
    "- The correlation has an upper and lower cap on a range, unlike covariance. It can only take values between +1 and -1. A correlation of +1 indicates that random variables have a direct and strong relationship.\n",
    "- On the other hand, the correlation of -1 indicates a strong inverse relationship, and an increase in one variable will lead to an equal and opposite decrease in the other variable. 0 means that the two numbers are independent.\n",
    "\n",
    "#### The Formula for Covariance and Correlation\n",
    "\n",
    "Let us express these concepts mathematically for two random variables, A and B, with mean values as Ua and Ub and standard deviation as Sa and Sb, respectively.\n",
    "\n",
    "Effectively we can define the relationship between the two:\n",
    "\n",
    "Covariance = Correlation * $Sa$ * $Sb$ \n",
    "Both correlations and covariance find application in statistical and financial analysis fields. Since correlation standardizes the connection, it is helpful in comparison of any two variables. In addition, it helps analysts develop strategies like pair trade and hedging for efficient returns on the portfolio and safeguarding these returns in terms of adverse movements in the stock market.\n",
    "\n",
    "We can calculate Covariance for only two variables. On the other hand, correlation can be calculated for multiple sets of numbers. Another factor that makes the correlation desirable to analysts compared to covariance.\n",
    "\n",
    "Correlation and covariance are very closely related to each other, and yet they differ a lot. Covariance defines the type of interaction, but correlation represents the type and the strength of this relationship. Due to this reason, correlation is often termed the special case of covariance. However, if one must choose between the two, most analysts prefer correlation as it remains unaffected by the changes in dimensions, locations, and scale. Also, since it is limited to a range of -1 to +1, it is useful to draw comparisons between variables across domains. However, an important limitation is that these concepts measure only the linear relationship.\n",
    "\n",
    "So, yeah, essentially everything I just included since the last bit of commentary was pasted into this markdown. Please don't sue me. Plllllleeeeeaaaasssssssseeeeeeeeeeeeeee. This is all for self-study, after all. \n",
    "\n",
    "***\n",
    "\n",
    "Now we are back to Medium.com. This time around, however, the author has 8.8k followers instead of  roughly 110. So, I'm feeling optimistic. [All the Distributions You Need to Know](https://towardsdatascience.com/all-the-distributions-you-need-to-know-ad570514987b#:~:text=A%20bimodal%20distribution%20has%20two,with%20a%20mixture%20coefficient%20α.) by Andre Ye. \n",
    "\n",
    "Note to self, I tried to use the tilde and it crossed-out all the content it's initial usage. Might want to look into that for later. \n",
    "\n",
    "Everything is defined by data, and so an understanding of distributions is essential in making sense of our world. According to the author, the distributions necessary to know are:\n",
    "- Binomial distribution\n",
    "- Bernoulli distribution\n",
    "- Poisson distribution\n",
    "- Bimodal distribution\n",
    "- Normal distribution\n",
    "- Uniform distribution\n",
    "\n",
    "So let's get into it. \n",
    "Also, future me, in case you're reading this and have lost all your memories, note that holding Option and Command simultaneously on a MacBook will allow you to select multiple lines in JupyterNotebook, which is exactl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3bc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
