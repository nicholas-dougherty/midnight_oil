{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a747f525-eb20-43bc-8d99-50562d652136",
   "metadata": {},
   "source": [
    "***\n",
    "1. Why is naive Bayes so “naive”?\n",
    "Naive Bayes is defined as naive because it assumes that all of the features in a data set are equally important and independent. As we know, these assumption are rarely true in real world scenario.\n",
    "***\n",
    "2. Assume I provide you with a data set. It contains many variables, some of which are highly correlated and you know about it. Your manager has asked you to run PCA. Would you remove correlated variables first and why?\n",
    "At very first glimpse, people might be tempted to say No, but that would be troublesome. Removing correlated variables is going to have a substantial effect on PCA because, in presence of correlated variables, the variance explained by a particular component gets inflated.\n",
    "For example: You have 3 variables in a data set, of which 2 are correlated. If you run PCA on this data set, the first principal component would exhibit twice the variance than it would exhibit with uncorrelated variables. Also, adding correlated variables lets PCA put more importance on those variable, which is misleading.\n",
    "***\n",
    "3. After analyzing your model, your manager has informed that your regression model is suffering from multicollinearity. How would you check if he’s true? Without losing any information, can you still build a better model?\n",
    "To check multicollinearity, we can create a correlation matrix to identify & remove variables having correlation above a certain threshold. In addition, we can use calculate VIF (variance inflation factor) to check the presence of multicollinearity. VIF value <= 4 suggests no multicollinearity whereas a value of >= 10 implies serious multicollinearity. Also, we can use tolerance as an indicator of multicollinearity.\n",
    "On the other side, removing correlated variables might lead to loss of information. In order to retain those variables, we can use penalized regression models like ridge or lasso regression.\n",
    "***\n",
    "4. When is Ridge regression favourable over Lasso regression?\n",
    "According to Hastie and Tibshirani, for few variables with medium / large sized effect, use Lasso; for many variables with small / medium sized effort, use Ridge regression.\n",
    "Lasso regression (L1) does both variable selection and parameter shrinkage, whereas Ridge regression only does parameter5 shrinkage and end up including all the coefficients in the model. For correlated variables, ridge regression might be a more preferred choice.\n",
    "***\n",
    "5. Both being tree based algorithm, how is random forest different from Gradient boosting algorithm (GBM)?\n",
    "Random forest uses bagging technique to make predictions while GBM uses boosting techniques to make predictions.\n",
    "In bagging technique, a data set is divided into N samples using randomized sampling. Then, using a single learning algorithm a model is build on all samples. Later, the resultant predictions are combined using voting or averaging. Bagging is done is parallel.\n",
    "In boosting, after the first round of predictions, the algorithm weighs misclassified predictions higher, such that they can be corrected in the succeeding round. This sequential process of giving higher weights to misclassified predictions continue until a stopping criterion is reached.\n",
    "As a result of that, random forest improves model accuracy by reducing variance. The trees grown are uncorrelated to maximize the decrease in variance. On the other hand, GBM improves accuracy my reducing both bias and variance in a model.\n",
    "***\n",
    "6. What cross validation technique would you use on time series data set? Would you consider K-fold or LOOCV?\n",
    "Unfortunately neither is suitable for time series data set.\n",
    "In time series problem, K-fold can be troublesome because there might be some pattern in year 4 or 5 which is not in year 3. Resampling the data set will separate these trends, and we might end up validation on past years, which is incorrect. Instead, we can use forward chaining strategy with 5 fold as shown below:\n",
    "fold 1 : training [1], test [2]\n",
    "fold 2 : training [1 2], test [3]\n",
    "fold 3 : training [1 2 3], test [4]\n",
    "fold 4 : training [1 2 3 4], test [5]\n",
    "fold 5 : training [1 2 3 4 5], test [6] where 1,2,3,4,5,6 represents “year”.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
